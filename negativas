import pandas as pd

# üëâ 1. Cargar archivos
archivo_terminos = '/Users/arnau/Documents/Script python teÃÅrminos busqueda/Informe de termes de cerca.csv'
archivo_palabras = '/Users/arnau/Documents/Script python teÃÅrminos busqueda/Informe de paraules clau de cerca.csv'

# Cargar saltando metadatos y usando el separador correcto
terminos_df = pd.read_csv(archivo_terminos, sep=';', skiprows=2, on_bad_lines='skip')
palabras_clave_df = pd.read_csv(archivo_palabras, sep=';', skiprows=2, on_bad_lines='skip')

# Separar columnas correctamente si est√°n en una sola columna
if terminos_df.shape[1] == 1:
    terminos_df = terminos_df.iloc[:, 0].str.split(",", expand=True)
if palabras_clave_df.shape[1] == 1:
    palabras_clave_df = palabras_clave_df.iloc[:, 0].str.split(",", expand=True)

# üëâ 2. Renombrar columnas
terminos_df.columns = [
    "Termino", "Concordancia", "Agregado", "Campa√±a", "Grupo",
    "Impresiones", "Interacciones", "CTR", "Moneda", "CPC medio", "Coste",
    "Tipo campa√±a", "Porc. conv.", "Conversiones", "Coste/conv.",
    "Extra1", "Extra2", "Extra3", "Extra4", "Extra5", "Extra6"
]

palabras_clave_df.columns = [
    "Estado", "Palabra clave", "Concordancia", "Campa√±a", "Grupo",
    "Estado2", "Motivo", "Moneda", "CPC m√°x.", "URL final", "URL m√≥vil",
    "Impresiones", "Interacciones", "CTR", "CPC medio", "Coste", 
    "Calidad", "Clics", "Porc. conv.", "Valor conv.", "Valor conv/coste",
    "Conversiones", "CPC medio 2", "Coste/conv.", "Extra1", "Extra2", 
    "Extra3", "Extra4", "Extra5", "Extra6", "Extra7", "Extra8", "Extra9"
]

# üëâ 3. Funci√≥n para limpiar texto
import unicodedata

def limpiar_texto(texto):
    if pd.isnull(texto):
        return ""
    # Eliminar acentos
    texto = unicodedata.normalize('NFD', str(texto))
    texto = texto.encode('ascii', 'ignore').decode('utf-8')
    
    return (
        texto
        .replace('"', '')
        .replace('[', '')
        .replace(']', '')
        .replace("(", "")
        .replace(")", "")
        .lower()
        .strip()
    )


# üëâ 4. Normalizar texto
terminos_df["Termino_limpio"] = terminos_df["Termino"].apply(limpiar_texto)
palabras_clave_df["Palabra_clave_limpia"] = palabras_clave_df["Palabra clave"].apply(limpiar_texto)

# Limpiar campos clave
terminos_df["Campa√±a"] = terminos_df["Campa√±a"].fillna("").str.strip()
terminos_df["Grupo"] = terminos_df["Grupo"].fillna("").str.strip()
palabras_clave_df["Campa√±a"] = palabras_clave_df["Campa√±a"].fillna("").str.strip()
palabras_clave_df["Grupo"] = palabras_clave_df["Grupo"].fillna("").str.strip()

# üëâ 5. Unir t√©rminos y claves por campa√±a y grupo
df_merged = terminos_df.merge(
    palabras_clave_df[["Campa√±a", "Grupo", "Palabra_clave_limpia", "Palabra clave"]],
    on=["Campa√±a", "Grupo"],
    how="left"
)


# üëâ 6. Analizar diferencias
def analizar_discrepancias(fila):
    term_words = set(fila["Termino_limpio"].split())
    keyword_words = set(fila["Palabra_clave_limpia"].split())
    extra = term_words - keyword_words
    faltantes = keyword_words - term_words
    return pd.Series({
        "Palabras_extra": ", ".join(sorted(extra)),
        "Palabras_faltantes": ", ".join(sorted(faltantes))
    })

discrepancias = df_merged.apply(analizar_discrepancias, axis=1)
df_resultado = pd.concat([df_merged, discrepancias], axis=1)

# üëâ 7. Filtrar y limpiar

# Extra
df_extra = df_resultado[df_resultado["Palabras_extra"] != ""][["Campa√±a", "Grupo", "Palabras_extra"]].drop_duplicates()

# Faltantes
df_faltantes = df_resultado[df_resultado["Palabras_faltantes"] != ""][["Campa√±a", "Grupo", "Termino", "Palabras_faltantes"]].drop_duplicates()

# üëâ 8. Exportar a dos CSVs
df_extra.to_csv("palabras_extra.csv", index=False)
df_faltantes.to_csv("palabras_faltantes.csv", index=False)

print("‚úÖ Exportado 'palabras_extra.csv' y 'palabras_faltantes.csv'")
# üëâ 9. Procesar palabras √∫nicas y limpias

# üëâ 9. Limpieza por palabra, excluyendo palabras ya incluidas en las keywords del grupo

def limpiar_lista(df, columna_palabras, output_file, keywords_df):
    resultado_limpio = []

    # Crear diccionario de grupo -> set de palabras clave limpias
    grupos_keywords = (
        keywords_df
        .dropna(subset=["Palabra_clave_limpia"])
        .groupby(["Campa√±a", "Grupo"])["Palabra_clave_limpia"]
        .apply(lambda x: set(" ".join(x).split()))
        .to_dict()
    )

    for _, row in df.iterrows():
        campa√±a = row["Campa√±a"]
        grupo = row["Grupo"]
        palabras = row[columna_palabras]

        # Separar, limpiar y filtrar
        palabras_separadas = [p.strip().lower() for p in palabras.split(",")]
        palabras_filtradas = [p for p in palabras_separadas if len(p) > 3]

        # Palabras clave ya existentes en ese grupo
        palabras_en_keywords = grupos_keywords.get((campa√±a, grupo), set())

        for palabra in palabras_filtradas:
            if palabra not in palabras_en_keywords:
                resultado_limpio.append((campa√±a, grupo, palabra))

    # Exportar
    df_limpio = pd.DataFrame(resultado_limpio, columns=["Campa√±a", "Grupo", "Palabra"]).drop_duplicates()
    df_limpio.to_csv(output_file, index=False)
    print(f"‚úÖ Exportado: {output_file}")

# Ejecutar limpieza
limpiar_lista(df_extra, "Palabras_extra", "palabras_extra_limpias.csv", palabras_clave_df)
limpiar_lista(df_faltantes, "Palabras_faltantes", "palabras_faltantes_limpias.csv", palabras_clave_df)


# üëâ 10. Calcular performance por palabra extra dentro del grupo

# Limpieza adicional para poder comparar t√©rminos sin acento
terminos_df["Termino_limpio"] = terminos_df["Termino"].apply(limpiar_texto)
terminos_df["Palabra_normalizada"] = terminos_df["Termino_limpio"]

# Cargar palabras extra limpias
df_palabras = pd.read_csv("palabras_extra_limpias.csv")

# Inicializar resultados
resultados = []

# Recorrer cada palabra extra
for _, row in df_palabras.iterrows():
    campa√±a = row["Campa√±a"]
    grupo = row["Grupo"]
    palabra = row["Palabra"]

    # Filtrar los t√©rminos en el mismo grupo/campa√±a que contengan esa palabra
    filtro = (
        (terminos_df["Campa√±a"] == campa√±a) &
        (terminos_df["Grupo"] == grupo) &
        (terminos_df["Palabra_normalizada"].str.contains(rf"\b{palabra}\b", regex=True))
    )
    subset = terminos_df[filtro]

    # Convertir columnas a num√©ricas (algunas pueden estar como texto)
    subset["Impresiones"] = pd.to_numeric(subset["Impresiones"], errors="coerce").fillna(0)
    subset["Interacciones"] = pd.to_numeric(subset["Interacciones"], errors="coerce").fillna(0)
    subset["CPC medio"] = pd.to_numeric(subset["CPC medio"], errors="coerce").fillna(0)
    subset["Conversiones"] = pd.to_numeric(subset["Conversiones"], errors="coerce").fillna(0)

    impresiones = int(subset["Impresiones"].sum())
    clics = int(subset["Interacciones"].sum())
    cpc_medio = subset["CPC medio"].mean() if clics > 0 else 0
    conversiones = int(subset["Conversiones"].sum())

    ratio_conversion = conversiones / clics if clics > 0 else 0
    coste_total = cpc_medio * clics
    coste_conversion = coste_total / conversiones if conversiones > 0 else 0

    resultados.append({
        "Campa√±a": campa√±a,
        "Grupo": grupo,
        "Palabra": palabra,
        "Impresiones": impresiones,
        "Clics": clics,
        "CPC medio": round(cpc_medio, 2),
        "Conversiones": conversiones,
        "Ratio de conversi√≥n": round(ratio_conversion, 3),
        "Coste de conversi√≥n": round(coste_conversion, 2)
    })

# Guardar resultados
df_resultado_perf = pd.DataFrame(resultados)
df_resultado_perf.to_csv("performance_extra.csv", index=False)
print("‚úÖ Exportado: performance_extra.csv")

# üëâ 11. Detectar t√©rminos que no contienen palabras que el grupo no ha cubierto nunca

faltantes_grupo = []

# 1. Palabras clave por grupo (las configuradas)
grupos_keywords = (
    palabras_clave_df
    .dropna(subset=["Palabra_clave_limpia"])
    .groupby(["Campa√±a", "Grupo"])["Palabra_clave_limpia"]
    .apply(lambda kws: set(" ".join(kws).split()))
    .to_dict()
)

# 2. Palabras que han aparecido realmente en t√©rminos por grupo
grupos_terminos = (
    terminos_df
    .dropna(subset=["Termino_limpio"])
    .groupby(["Campa√±a", "Grupo"])["Termino_limpio"]
    .apply(lambda ts: set(" ".join(ts).split()))
    .to_dict()
)

# 3. Recorrer t√©rminos individuales y detectar los que faltan algo importante
for _, row in terminos_df.iterrows():
    campa√±a = row["Campa√±a"]
    grupo = row["Grupo"]
    termino = row["Termino_limpio"]
    palabras_termino = set(termino.split())

    # Palabras clave configuradas para el grupo
    palabras_esperadas = grupos_keywords.get((campa√±a, grupo), set())
    palabras_cubiertas = grupos_terminos.get((campa√±a, grupo), set())

    # Palabras esperadas que NUNCA han sido cubiertas por ning√∫n t√©rmino
    palabras_nunca_activadas = palabras_esperadas - palabras_cubiertas

    # Si el t√©rmino no contiene alguna de esas palabras nunca activadas, la reportamos
    palabras_faltantes = palabras_nunca_activadas - palabras_termino

    if palabras_faltantes:
        faltantes_grupo.append({
            "Campa√±a": campa√±a,
            "Grupo": grupo,
            "Termino": termino,
            "Palabras_faltantes": ", ".join(sorted(palabras_faltantes))
        })

# Exportar CSV con t√©rmino + faltantes reales
df_faltantes_grupo = pd.DataFrame(faltantes_grupo).drop_duplicates()
df_faltantes_grupo.to_csv("faltantes_por_grupo.csv", index=False)
print("‚úÖ Exportado: faltantes_por_grupo.csv")

# Guardar resultados
df_resultado_perf = pd.DataFrame(resultados)
df_resultado_perf.to_csv("performance_extra.csv", index=False)
print("‚úÖ Exportado: performance_extra.csv")
